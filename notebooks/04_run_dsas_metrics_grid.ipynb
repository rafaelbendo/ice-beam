{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1780b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from is2retreat.config import Params\n",
    "from is2retreat.pipeline import run_workflow\n",
    "from is2retreat.bluff import process_cluster_with_reference\n",
    "from is2retreat.metrics import compute_cluster_statistics\n",
    "\n",
    "P = Params()\n",
    "TRACK_ID = 129\n",
    "\n",
    "CLUSTER_SIZES   = [6, 12, 18, 24, 30, 36, 42]\n",
    "BIAS_TOLERANCES = [0.25, 0.5, 0.75, 1.0]\n",
    "OUTFILE = Path(\"DSAS_clusters.csv\")\n",
    "\n",
    "existing = pd.read_csv(OUTFILE, dtype={\"track_id\": str}) if OUTFILE.exists() else pd.DataFrame()\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for cs in CLUSTER_SIZES:\n",
    "    for tol in BIAS_TOLERANCES:\n",
    "        P.CLUSTER_DISTANCE_M = float(cs)\n",
    "        P.BIAS_TOLERANCE = float(tol)\n",
    "\n",
    "        already = existing[\n",
    "            (existing.get(\"track_id\") == f\"{int(TRACK_ID):04d}\") &\n",
    "            (existing.get(\"ClusterSize\") == cs) &\n",
    "            (existing.get(\"bias_tolerance\") == tol)\n",
    "        ]\n",
    "        if not already.empty:\n",
    "            print(f\"Skip cs={cs}, tol={tol} (exists)\")\n",
    "            continue\n",
    "\n",
    "        (\n",
    "            summary_fam,\n",
    "            summary_clust,\n",
    "            dataset_clean,\n",
    "            clusters_gdf,\n",
    "            selected_clusters,\n",
    "            filtered_profiles,\n",
    "            bias_summary,\n",
    "            bias_df,\n",
    "        ) = run_workflow(TRACK_ID, dataset_raw, shoreline_gdf, P, verbose=False)\n",
    "\n",
    "        if selected_clusters is None or selected_clusters.empty:\n",
    "            continue\n",
    "\n",
    "        for fam in selected_clusters[\"gt_family\"].unique():\n",
    "            fam_clusters = selected_clusters.query(\"gt_family == @fam\").copy()\n",
    "\n",
    "            for cid in fam_clusters[\"cluster_id\"].unique():\n",
    "                bluff_df, y_ref = process_cluster_with_reference(\n",
    "                    filtered_profiles=filtered_profiles,\n",
    "                    selected_clusters=fam_clusters,\n",
    "                    params=P,\n",
    "                    cluster_id=int(cid),\n",
    "                    gt_family=str(fam),\n",
    "                    which=\"first\",\n",
    "                    bias_df=bias_df,\n",
    "                    debug=False,\n",
    "                )\n",
    "                if bluff_df is None or bluff_df.empty:\n",
    "                    continue\n",
    "\n",
    "                stats = compute_cluster_statistics(\n",
    "                    bluff_df,\n",
    "                    confidence=P.CONFIDENCE,\n",
    "                    min_span_days=P.MIN_SPAN_DAYS,\n",
    "                )\n",
    "\n",
    "                all_rows.append({\n",
    "                    \"track_id\": f\"{int(TRACK_ID):04d}\",\n",
    "                    \"ClusterSize\": int(cs),\n",
    "                    \"bias_tolerance\": float(tol),\n",
    "                    \"gt_family\": fam,\n",
    "                    \"cluster_id\": int(cid),\n",
    "                    **stats,\n",
    "                    \"angle_deg\": float(fam_clusters.loc[fam_clusters[\"cluster_id\"] == cid, \"angle_deg\"].iloc[0]) if \"angle_deg\" in fam_clusters.columns else np.nan,\n",
    "                    \"center_lat\": float(fam_clusters.loc[fam_clusters[\"cluster_id\"] == cid, \"center_lat\"].iloc[0]) if \"center_lat\" in fam_clusters.columns else np.nan,\n",
    "                    \"center_lon\": float(fam_clusters.loc[fam_clusters[\"cluster_id\"] == cid, \"center_lon\"].iloc[0]) if \"center_lon\" in fam_clusters.columns else np.nan,\n",
    "                })\n",
    "\n",
    "new_df = pd.DataFrame(all_rows)\n",
    "combined = pd.concat([existing, new_df], ignore_index=True) if not existing.empty else new_df\n",
    "combined.to_csv(OUTFILE, index=False)\n",
    "combined.tail(10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
